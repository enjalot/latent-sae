{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enjalot/code/latent-sae/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton not installed, using eager implementation of SAE decoder.\n"
     ]
    }
   ],
   "source": [
    "# try getting the Eleuther SAE running via this lib\n",
    "from latentsae import Sae\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 4/4 [03:02<00:00, 45.69s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:34<00:00,  8.68s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B\")\n",
    "inputs = tokenizer(\"Hello, world!\", return_tensors=\"pt\")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\"We the people hold these truths to be self-evident, that all men are created equal, that they are endowed by their Creator with certain unalienable Rights, that among these are Life, Liberty and the pursuit of Happiness.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_inputs = tokenizer(inputs, return_tensors=\"pt\",truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 48])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_inputs.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDDEN STATES 33\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "   outputs = model(**tokenized_inputs, output_hidden_states=True)\n",
    "   print(\"HIDDEN STATES\", len(outputs.hidden_states))\n",
    "   llama_embeddings = outputs.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 48, 4096])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_embeddings[23].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files: 100%|██████████| 2/2 [03:42<00:00, 111.49s/it]\n",
      "Dropping extra args {'multi_topk': True}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# sae = Sae.load_from_hub(\"EleutherAI/sae-llama-3-8b-32x\", hookpoint=\"layers.10\")\n",
    "sae = Sae.load_from_hub(\"EleutherAI/sae-llama-3.1-8b-64x\", \"layers.23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_latents = sae.encode(llama_embeddings[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 48, 32])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_latents.top_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 48, 32])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_latents.top_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 34496,  28859,  32150,  59087,  53862,  78388,  13486,   3613, 110039,\n",
       "        114296,  56223,  71909,  87574, 111785,  10220,  86508,  79681, 103532,\n",
       "         69833, 107594, 129910, 115369, 126513, 103850,  11678,  46127,  55643,\n",
       "         10455,  65354,  82677,  30749,  33673, 106180,   4642, 127695,  40376,\n",
       "          4796, 104244,  52024,  97119,  74896,  10227, 108945,  73192,  98653,\n",
       "         31088,  47750, 104827,  65571,  78962,  82057, 122440,  15351,  14032,\n",
       "         21024,  46235, 106380,  64058,  73782,  53153,  94998,  83077, 121363,\n",
       "         67037,  95699,   2610,  97276,  88087, 109084, 101368,  81898,  80264,\n",
       "        119419,  40167, 102092,  16318,  91610,  99694,  30839,  84988,  14935,\n",
       "         23503,  55780,   7549,  47055,  66790,  88861,  27737,  21785, 122859,\n",
       "         36030, 115979,  49515,  83508,  13175,  41546,  63746,  84089, 101567,\n",
       "         52995,  58830,  17459,  52256,  75069, 124610, 100739,  34133,  90252,\n",
       "         37650,  66793, 124689,  82839,  32998,  20498, 122295,  53957,  90030,\n",
       "        121085, 102991,  89355,   2970,  87110, 117620,  25940,  70516,  32477,\n",
       "        121047,  75997,  41988,  25717,  19987, 128775,  11280,   6208,  19989,\n",
       "         84742,  47533,  32881,  97336, 112210,  17906,   8112,  28364,  98479,\n",
       "         53963,  41189,  36594,  27539,  81544,  11242,   2439,  21950, 115714,\n",
       "         53636, 100983,  34879,  80208,  11105,  24727,  45862,  31023,  99404,\n",
       "         79606,  31564,  37251,  43778,  34347,  11332,  38033,  97323,  89085,\n",
       "         99852,  88239,  99537,  92954,  11223,  47619,  64351,  27854, 104888,\n",
       "        121733,  25321,  80517,    216,  99512, 118727,  94871, 111958,  66241,\n",
       "        107959, 108826,   2103])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_latents.top_indices[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262144"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " 'W_dec',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_compiled_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'b_dec',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'cfg',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'd_in',\n",
       " 'decode',\n",
       " 'device',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'dump_patches',\n",
       " 'encode',\n",
       " 'encoder',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'load_from_disk',\n",
       " 'load_from_hub',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_latents',\n",
       " 'parameters',\n",
       " 'pre_acts',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'remove_gradient_parallel_to_decoder_directions',\n",
       " 'requires_grad_',\n",
       " 'save_to_disk',\n",
       " 'select_topk',\n",
       " 'set_decoder_norm_to_unit_norm',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SaeConfig(expansion_factor=64, normalize_decoder=True, num_latents=0, k=32, signed=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
